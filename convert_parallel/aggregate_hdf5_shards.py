"""
èšåˆ HDF5 å¹¶è¡Œè½¬æ¢ç”Ÿæˆçš„ shards æˆä¸€ä¸ªå®Œæ•´çš„ LeRobot Dataset
"""

import argparse
import logging

from lerobot.datasets.aggregate import aggregate_datasets
from lerobot.utils.utils import init_logging


def main():
    parser = argparse.ArgumentParser(
        description="èšåˆ HDF5 å¹¶è¡Œè½¬æ¢ç”Ÿæˆçš„ shards æˆä¸€ä¸ªå®Œæ•´çš„ LeRobot Dataset"
    )

    parser.add_argument(
        "--repo-id",
        type=str,
        required=True,
        help="åŸºç¡€ repository IDï¼ˆä¸åŒ…å« _world_X_rank_Y åç¼€ï¼‰",
    )
    parser.add_argument(
        "--num-shards",
        type=int,
        required=True,
        help="Shard çš„æ•°é‡ï¼ˆåº”è¯¥ç­‰äº convert_hdf5_shards.py ä¸­çš„ --workers æ•°é‡ï¼‰",
    )
    parser.add_argument(
        "--output-repo-id",
        type=str,
        default=None,
        help="è¾“å‡ºæ•°æ®é›†çš„ repo_idï¼ˆé»˜è®¤ä½¿ç”¨ --repo-id çš„å€¼ï¼‰",
    )

    args = parser.parse_args()

    # åˆå§‹åŒ–æ—¥å¿—
    init_logging()

    # æ„é€  shard repo_ids
    repo_ids = [f"{args.repo_id}_world_{args.num_shards}_rank_{rank}" for rank in range(args.num_shards)]

    # ç¡®å®šè¾“å‡º repo_id
    output_repo_id = args.output_repo_id if args.output_repo_id else args.repo_id

    # æ‰“å°ä¿¡æ¯
    print(f"ğŸ“Š Aggregation Configuration:")
    print(f"   Base repo ID: {args.repo_id}")
    print(f"   Number of shards: {args.num_shards}")
    print(f"   Output repo ID: {output_repo_id}")
    print()
    print(f"ğŸ“ Shards to aggregate:")
    for repo_id in repo_ids:
        print(f"   - {repo_id}")
    print()

    # æ‰§è¡Œèšåˆ
    logging.info(f"Starting aggregation of {len(repo_ids)} datasets into {output_repo_id}")
    aggregate_datasets(repo_ids, output_repo_id)

    print(f"\nâœ¨ Aggregation complete!")
    print(f"Aggregated dataset: {output_repo_id}")
    return 0


if __name__ == "__main__":
    exit(main())
